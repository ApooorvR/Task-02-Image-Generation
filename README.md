# Task 02 â€“ Image Generation using Pre-trained Models

## Objective
The objective of this task is to generate images from textual descriptions using pre-trained generative models.

## Approach
A pre-trained Stable Diffusion model was used to convert text prompts into realistic images. The model was utilized directly without any additional training.

## Tools & Technologies
- Python
- PyTorch
- Hugging Face Diffusers
- Stable Diffusion (Pre-trained Model)

## Implementation Steps
1. Loaded the Stable Diffusion pipeline
2. Provided descriptive text prompts
3. Generated images based on the input text
4. Saved generated images locally

## Result
The model successfully produced visually meaningful images that matched the given text prompts.

## Learning Outcome
- Understanding text-to-image generation
- Working with diffusion-based generative models
- Prompt engineering for better image quality
